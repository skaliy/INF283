{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "sys.path.append(\"../classes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from math import log2\n",
    "from Node import * \n",
    "from ImpurityMeasure import * \n",
    "from PandasToNumpy import PandasToNumpy\n",
    "from ModelSelection import * \n",
    "from Metrics import * \n",
    "import operator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the cleaned csv file\n",
    "Data cleaning is done by<i> clean_data.ipynb</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DIR = %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = (f'{NB_DIR}/').replace('nbs/','')+'csv/'\n",
    "CLEANED_FILE_NAME = 'mushrooms_cleaned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5644, 23)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH+CLEANED_FILE_NAME)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5644, 23)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>u</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>k</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>l</td>\n",
       "      <td>h</td>\n",
       "      <td>v</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>p</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>h</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>p</td>\n",
       "      <td>...</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>l</td>\n",
       "      <td>h</td>\n",
       "      <td>v</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "3294     e         f           f         e       t    n               f   \n",
       "121      e         x           y         w       t    a               f   \n",
       "4355     p         f           y         g       f    f               f   \n",
       "4240     p         x           s         b       t    f               f   \n",
       "3173     p         x           f         g       f    f               f   \n",
       "\n",
       "     gill-spacing gill-size gill-color   ...   stalk-surface-below-ring  \\\n",
       "3294            c         b          u   ...                          s   \n",
       "121             c         b          g   ...                          s   \n",
       "4355            c         b          g   ...                          k   \n",
       "4240            c         b          p   ...                          s   \n",
       "3173            c         b          p   ...                          k   \n",
       "\n",
       "     stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "3294                      g                      w         p          w   \n",
       "121                       w                      w         p          w   \n",
       "4355                      p                      p         p          w   \n",
       "4240                      w                      w         p          w   \n",
       "3173                      n                      n         p          w   \n",
       "\n",
       "     ring-number ring-type spore-print-color population habitat  \n",
       "3294           o         p                 k          v       d  \n",
       "121            o         p                 n          n       m  \n",
       "4355           o         l                 h          v       p  \n",
       "4240           o         p                 h          s       g  \n",
       "3173           o         l                 h          v       p  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = PandasToNumpy.dataframe_to_numpy(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = X[1:], y[1:] #drop the header "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = ModelSelection.train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(arr_list): \n",
    "    '''\n",
    "    Find the number of unique values in the the array and return a dictionary with the unique values as key and the total number of them as value\n",
    "    '''\n",
    "    result = {} \n",
    "    for value in arr_list: \n",
    "        if value not in result: result[value] = 1\n",
    "        else: result[value]+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_prediction(x,node): #x = [0,0,1,1]\n",
    "    '''\n",
    "    Arguments:\n",
    "        x: 1D array. Example: values for an observation in the mushroom dataset [0,1,0,1....](23 columns)\n",
    "        node: Node objekt\n",
    "    \n",
    "    If it is miss classified it will return None, otherwise it will return 0 or 1\n",
    "    '''\n",
    "    while len(x) > 0: \n",
    "        cat_var = x[node.category] #Rot sin kategori, så da velges posisjon 0 for eksempel \n",
    "        x = np.delete(x, node.category, axis=0)\n",
    "        if cat_var not in node.children: #miss classification  \n",
    "            node.data\n",
    "            return None\n",
    "        child_node = node.children[cat_var]\n",
    "        if child_node.isLeaf: \n",
    "            return child_node.data\n",
    "        node = child_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, node):\n",
    "    '''\n",
    "    Arguments:\n",
    "        X: 2D array. Example: Alle the observations that you want to predict on the mushroom dataset\n",
    "        node: Node object\n",
    "    \n",
    "    return an 1D array with all the predictions\n",
    "    '''\n",
    "    result = []\n",
    "    for i in X: \n",
    "        result.append(case_prediction(i,node))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(categories, y, impurity_measure): \n",
    "    '''\n",
    "    Arguments:\n",
    "        categories: training data with the remaining data. Each of the rows are a category. \n",
    "        y: true values for the training data \n",
    "        impurity_measure: String value if it's 'entropy' or 'gini'\n",
    "\n",
    "    Return the information gain with highest value (The best category to select) \n",
    "    '''\n",
    "    impurity_measure_method = getattr(ImpurityMeasure(), impurity_measure)\n",
    "    \n",
    "    impurity_measure_src = impurity_measure_method(y)\n",
    "    best_ig_score = []\n",
    "    for cat in categories:   #Example: cat can be cap-shape column.#cap-shape contains the variables: f, b, x \n",
    "      \n",
    "        variables_dic = {}\n",
    "        impurity_measure_of_branches = 0 if impurity_measure=='entropy' else impurity_measure_src\n",
    "        \n",
    "        #Variabel and y values for them\n",
    "        for index,var in enumerate(cat): \n",
    "            if var not in variables_dic: variables_dic[var] = []\n",
    "            variables_dic[var].append(y[index])\n",
    " \n",
    "        #Calculate impurity measure for each of the variables\n",
    "        for key, var_y in variables_dic.items(): \n",
    "            result = impurity_measure_method(var_y)*(len(var_y)/len(y))\n",
    "            \n",
    "            if(impurity_measure == 'entropy'):\n",
    "                impurity_measure_of_branches += result\n",
    "            else: \n",
    "                 impurity_measure_of_branches -= result\n",
    "                \n",
    "        information_gain = impurity_measure_src - impurity_measure_of_branches \n",
    "        best_ig_score.append(information_gain)\n",
    "        \n",
    "    return np.argmax(best_ig_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dominant_value(values_dic): \n",
    "    '''\n",
    "    value_dic: key is a binary number 0 or 1 and the value for them are number of them in a category. \n",
    "    return the key with the highest value in the dictionary\n",
    "    '''\n",
    "    return max(values_dic, key=values_dic.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_tree(X,y, node, impurity_measure): \n",
    "    '''\n",
    "    Arguments:\n",
    "        X: training data \n",
    "        y: true values for the training data \n",
    "        node: Node object \n",
    "        impurity_measure: String value if it's 'entropy' or 'gini'\n",
    "\n",
    "    Creates the tree\n",
    "    '''\n",
    "    #Find best category \n",
    "    if len(X) == 0: \n",
    "        return \n",
    "    else: \n",
    "        index = find_best_split(X,y,impurity_measure) #Finding the index of the best category to split on\n",
    "        \n",
    "        node.category = index\n",
    "        node.data = X[index] #add the category data to the node \n",
    "        child_dic = count_values(node.data) #count num variables for the category \n",
    "    \n",
    "        for i in child_dic.keys(): #Add variable name and Node as child to the Node\n",
    "            node.add_child(i,Node()) \n",
    "    \n",
    "        for var, child_node in node.children.items():\n",
    "            child_node.parent_node = node\n",
    "            indices = [i for i, x in enumerate(node.data) if x == var] #the indices for the varible in the parent node data\n",
    "            result = count_values(y[indices]) #check how many true and false values for the variable in the category\n",
    "            if len(result) == 1: \n",
    "                child_node.data = next(iter(result.keys())) #The result is clean, so we give a value.\n",
    "                child_node.isLeaf = True\n",
    "            \n",
    "            elif (len(X) == 1): #They are still not clean, but then you have to find the dominant value\n",
    "                child_node.data = find_dominant_value(result)\n",
    "                child_node.isLeaf = True\n",
    "                \n",
    "            if not child_node.isLeaf:\n",
    "                node_X = np.delete(X, index, axis=0)\n",
    "                create_tree(node_X[:,indices],y[indices], child_node, impurity_measure) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(X,y,impurity_measure = 'entropy',  pruning=False): \n",
    "    '''\n",
    "    Arguments:\n",
    "        X: training data \n",
    "        y: true values for the training data \n",
    "        impurity_measure: default impurity measure is 'entropy'. Alternatives: 'gini'\n",
    "        pruning: default False\n",
    "\n",
    "    If the user want to use pruning on the three, the training set will be divided into two subsets\n",
    "    Then we will create the three and use the pruning set to prune the tree, otherwise it will just create a tree. \n",
    "    Returns the tree\n",
    "    '''\n",
    "    X_pruning, y_pruning = [],[]\n",
    "    if pruning: \n",
    "        X, X_pruning, y, y_pruning =  ModelSelection.train_test_split(X,y) #get pruning set the same was as test set, but this time we split the training set in two subsets. \n",
    "        \n",
    "   \n",
    "    root = Node()\n",
    "\n",
    "    #X.T so that each of the categories comes on a line\n",
    "    create_tree(X.T,y, root,impurity_measure)\n",
    "    if pruning: \n",
    "        while pruning: \n",
    "            pruning = False \n",
    "            pruning_pred = predict(X_pruning,root) #Vanlig predikt \n",
    "            pruning_accuracy = Metrics.accuracy(y_pruning, pruning_pred)\n",
    "\n",
    "            for children in root.children.values():\n",
    "                leaf_node  = find_leaf(children)\n",
    "                change_made = prune(leaf_node, pruning_accuracy,X_pruning,y_pruning, root)\n",
    "                if (not pruning) and change_made: pruning = change_made\n",
    "            \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_leaf(node):\n",
    "    '''\n",
    "    Arguments:\n",
    "        node: Node object. Example a child node of root. \n",
    "    \n",
    "    return the leaf node for the node. \n",
    "    '''\n",
    "    if node.isLeaf: \n",
    "        return (node)\n",
    "    else: \n",
    "        for key, child in node.children.items():\n",
    "            return find_leaf(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parent_variabel(parent_node,grand_parent_node):\n",
    "    '''\n",
    "    Find the variabel value in grandparent node, so we can change the variables node to another node. In our case parent_variable_in_grand_parent\n",
    "\n",
    "    returns the variabel value. \n",
    "    '''\n",
    "    for key, node in grand_parent_node.children.items(): \n",
    "        if node == parent_node: return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(leaf_node, pruning_accuracy, X_pruning, y_pruning, tree): \n",
    "    '''\n",
    "    Arguments:\n",
    "        leaf_node: leaf_node of a subtree\n",
    "        pruning_accuracy: accurcy on the pruning set \n",
    "        X_pruning: pruning set\n",
    "        y_pruning: true values for the pruning set\n",
    "        tree: the root node \n",
    "\n",
    "    The method checks if the accurcy on the pruning set increases if we change the parent node of the leaf_node to leaf node with the output 0 and/or 1. \n",
    "    The parent node will be the new leaf if it imporves the accuracy and the children of the parent node will be removed from the three\n",
    "    return variable says if there have been any changes in the three (True/False)\n",
    "    '''\n",
    "    prun_acc = pruning_accuracy\n",
    "    changes = False \n",
    "    parent = leaf_node.parent_node\n",
    "    \n",
    "    child_values_to_check = []\n",
    "    child_values_to_check.append(bool(leaf_node.data))\n",
    "    if(len(parent.children) >1): \n",
    "        child_values_to_check.append(not leaf_node.data)\n",
    "    \n",
    "    for i in child_values_to_check: \n",
    "        grand_parent = parent.parent_node\n",
    "\n",
    "        dummy_node = Node()\n",
    "        dummy_node.category = parent.category\n",
    "        dummy_node.isLeaf = True\n",
    "        dummy_node.data = i\n",
    "        dummy_node.parent_node = grand_parent\n",
    "\n",
    "        if not (grand_parent == None): \n",
    "            parent_variable_in_grand_parent = find_parent_variabel(parent, grand_parent)\n",
    "            grand_parent.children[parent_variable_in_grand_parent] = dummy_node\n",
    "  \n",
    "        #predict\n",
    "        pred = predict(X_pruning, tree)\n",
    "        pred_acc = Metrics.accuracy(y_pruning,pred)\n",
    "    \n",
    "        if (prun_acc < pred_acc): \n",
    "            prun_acc = pred_acc\n",
    "            parent = dummy_node\n",
    "            changes = True\n",
    "        elif not (grand_parent == None ): \n",
    "            grand_parent.children[parent_variable_in_grand_parent] = parent\n",
    "    return changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node):\n",
    "    '''\n",
    "    Print the tree with recursion \n",
    "    '''\n",
    "    if node.isLeaf: \n",
    "        print(\"-----Leaf_value------\")\n",
    "        print(node.data)\n",
    "        print()\n",
    "    else: \n",
    "        for key, child in node.children.items():\n",
    "            if not child.isLeaf:print(key, child.children.keys())\n",
    "            print_tree(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Root: \"+ str(tree.children.keys()))\n",
    "#print()\n",
    "#print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = learn(X_train,y_train, pruning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(X_test,tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Metrics.accuracy(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance measurement\n",
    "Confusion matrix and recall and precison calculation with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the None values in y_pred to a binary number.\n",
    "#Return fixed y_pred \n",
    "def missclassification_binary(y_test,y_pred): \n",
    "    binary_y_pred = []\n",
    "    for idx,i in enumerate(y_pred):\n",
    "        if i == None: \n",
    "            i = not y_test[idx]\n",
    "        binary_y_pred.append(i)\n",
    "    return binary_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = missclassification_binary(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[413,   0],\n",
       "       [  0, 715]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 discussion\n",
    "I am shuffling the dataframe before I start to use it with <i> df = df.sample(frac=1)</i>\n",
    "In addition I take out random rows for the test/pruning set. I am doing this to be sure that the data is randomly sampled.\n",
    "Default value for test/pruning sets are 20% of the data set we give into the train_test_split method.\n",
    "\n",
    "\n",
    "Entropy gives a better result than gini. The pruning has no effect on the tree when we are using entropy.\n",
    "On gini it makes the result vary slightly.\n",
    "The reason why pruning sometimes will reduce the size of the tree is that the sum of errors for leaf nodes (children) for a node is greater than the sum of error for that node. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn decsion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Metrics.accuracy(y_test, sk_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 discussion\n",
    "My implementation gives the same result as sklearn decsion tree with entropy as impurity measurement.\n",
    "Both classifiers have a 100% accuracy on the test set(20% of the dataset).<br>\n",
    "Pruning is something which is planned to be done in future in sklearn(https://datascience.stackexchange.com/questions/26087/sklearn-missing-pruning-for-decision-trees), so I can't compare that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT158",
   "language": "python",
   "name": "dat158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
